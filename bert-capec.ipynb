{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7961167,"sourceType":"datasetVersion","datasetId":4683242},{"sourceId":42895,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":36036}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-03T07:27:12.085039Z","iopub.execute_input":"2024-05-03T07:27:12.085891Z","iopub.status.idle":"2024-05-03T07:27:25.369020Z","shell.execute_reply.started":"2024-05-03T07:27:12.085856Z","shell.execute_reply":"2024-05-03T07:27:25.367999Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport shutil\nimport sys   ","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:25.371405Z","iopub.execute_input":"2024-05-03T07:27:25.372237Z","iopub.status.idle":"2024-05-03T07:27:29.579973Z","shell.execute_reply.started":"2024-05-03T07:27:25.372196Z","shell.execute_reply":"2024-05-03T07:27:29.579182Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_path = \"/kaggle/input/code-injection-6labels-balance/code_injection_6labels_balance.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:29.581067Z","iopub.execute_input":"2024-05-03T07:27:29.581565Z","iopub.status.idle":"2024-05-03T07:27:29.585921Z","shell.execute_reply.started":"2024-05-03T07:27:29.581529Z","shell.execute_reply":"2024-05-03T07:27:29.585037Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(train_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:29.587969Z","iopub.execute_input":"2024-05-03T07:27:29.588257Z","iopub.status.idle":"2024-05-03T07:27:29.847126Z","shell.execute_reply.started":"2024-05-03T07:27:29.588232Z","shell.execute_reply":"2024-05-03T07:27:29.846057Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"target_list = [\"000 - Normal\", '126 - Path Traversal', \n               '242 - Code Injection', '274 - HTTP Verb Tampering', \n               '66 - SQL Injection', '88 - OS Command Injection']","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:29.848601Z","iopub.execute_input":"2024-05-03T07:27:29.849343Z","iopub.status.idle":"2024-05-03T07:27:29.853816Z","shell.execute_reply.started":"2024-05-03T07:27:29.849303Z","shell.execute_reply":"2024-05-03T07:27:29.852991Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train, validate, test = np.split(df.sample(frac=1, random_state=42),[int(.6*len(df)), int(.8*len(df))])","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:29.854999Z","iopub.execute_input":"2024-05-03T07:27:29.855259Z","iopub.status.idle":"2024-05-03T07:27:29.890454Z","shell.execute_reply.started":"2024-05-03T07:27:29.855236Z","shell.execute_reply":"2024-05-03T07:27:29.889610Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n  return bound(*args, **kwds)\n","output_type":"stream"}]},{"cell_type":"code","source":"# hyperparameters\nMAX_LEN = 256\nTRAIN_BATCH_SIZE = 32\nVALID_BATCH_SIZE = 32\nEPOCHS = 2\nLEARNING_RATE = 1e-05","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:29.891623Z","iopub.execute_input":"2024-05-03T07:27:29.891880Z","iopub.status.idle":"2024-05-03T07:27:29.896240Z","shell.execute_reply.started":"2024-05-03T07:27:29.891857Z","shell.execute_reply":"2024-05-03T07:27:29.895230Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModel\nfrom transformers import BertTokenizer, BertModel\nfrom transformers import DistilBertTokenizer, DistilBertModel","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:29.897337Z","iopub.execute_input":"2024-05-03T07:27:29.897605Z","iopub.status.idle":"2024-05-03T07:27:33.606931Z","shell.execute_reply.started":"2024-05-03T07:27:29.897582Z","shell.execute_reply":"2024-05-03T07:27:33.606114Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:33.607927Z","iopub.execute_input":"2024-05-03T07:27:33.608449Z","iopub.status.idle":"2024-05-03T07:27:34.390903Z","shell.execute_reply.started":"2024-05-03T07:27:33.608423Z","shell.execute_reply":"2024-05-03T07:27:34.389914Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bf5919f04614641b963b75eb0e51e86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17a102ac70ca4b4bac08df9d52588b3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3fe8f4a4eee4903a8acae0dbded80f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deae512c02b747ada91c689f78015836"}},"metadata":{}}]},{"cell_type":"code","source":"class CustomDataset(torch.utils.data.Dataset):\n\n    def __init__(self, df, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.df = df\n        self.title = df['text']\n        self.targets = self.df[target_list].values\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.title)\n\n    def __getitem__(self, index):\n        title = str(self.title[index])\n        title = \" \".join(title.split())\n\n        inputs = self.tokenizer.encode_plus(\n            title,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True,\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': inputs['input_ids'].flatten(),\n            'attention_mask': inputs['attention_mask'].flatten(),\n            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n            'targets': torch.FloatTensor(self.targets[index])\n        }","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:34.393615Z","iopub.execute_input":"2024-05-03T07:27:34.394465Z","iopub.status.idle":"2024-05-03T07:27:34.402668Z","shell.execute_reply.started":"2024-05-03T07:27:34.394425Z","shell.execute_reply":"2024-05-03T07:27:34.401794Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train = train.reset_index(drop=True)\nvalidate = validate.reset_index(drop=True)\ntest = test.reset_index(drop=True)\n\ntrain = CustomDataset(train, tokenizer, MAX_LEN)\nvalidate= CustomDataset(validate, tokenizer, MAX_LEN)\ntest = CustomDataset(test, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:34.403811Z","iopub.execute_input":"2024-05-03T07:27:34.404093Z","iopub.status.idle":"2024-05-03T07:27:34.426453Z","shell.execute_reply.started":"2024-05-03T07:27:34.404070Z","shell.execute_reply":"2024-05-03T07:27:34.425760Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_data_loader = torch.utils.data.DataLoader(train, \n    batch_size=TRAIN_BATCH_SIZE,\n    shuffle=True,\n    num_workers=0\n)\n\nval_data_loader = torch.utils.data.DataLoader(validate, \n    batch_size=VALID_BATCH_SIZE,\n    shuffle=False,\n    num_workers=0\n)\ntest_data_loader = torch.utils.data.DataLoader(test, \n    batch_size=VALID_BATCH_SIZE,\n    shuffle=False,\n    num_workers=0\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:34.427445Z","iopub.execute_input":"2024-05-03T07:27:34.427762Z","iopub.status.idle":"2024-05-03T07:27:34.433980Z","shell.execute_reply.started":"2024-05-03T07:27:34.427737Z","shell.execute_reply":"2024-05-03T07:27:34.432878Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:34.435425Z","iopub.execute_input":"2024-05-03T07:27:34.435714Z","iopub.status.idle":"2024-05-03T07:27:34.501719Z","shell.execute_reply.started":"2024-05-03T07:27:34.435692Z","shell.execute_reply":"2024-05-03T07:27:34.500731Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_ckp(checkpoint_fpath, model):\n    \"\"\"\n    checkpoint_path: path to save checkpoint\n    model: model that we want to load checkpoint parameters into       \n    optimizer: optimizer we defined in previous training\n    \"\"\"\n    # load check point\n    checkpoint = torch.load(checkpoint_fpath)\n    # initialize state_dict from checkpoint to model\n    model.load_state_dict(checkpoint['state_dict'])\n    # initialize optimizer from checkpoint to optimizer\n#     optimizer.load_state_dict(checkpoint['optimizer'])\n    # initialize valid_loss_min from checkpoint to valid_loss_min\n#     valid_loss_min = checkpoint['valid_loss_min']\n    # return model, optimizer, epoch value, min validation loss \n    return model\n#     , optimizer, checkpoint['epoch'], valid_loss_min.item()\n\ndef save_ckp(state, is_best, checkpoint_path, best_model_path):\n    \"\"\"\n    state: checkpoint we want to save\n    is_best: is this the best checkpoint; min validation loss\n    checkpoint_path: path to save checkpoint\n    best_model_path: path to save best model\n    \"\"\"\n    f_path = checkpoint_path\n    # save checkpoint data to the path given, checkpoint_path\n    torch.save(state, f_path)\n    # if it is a best model, min validation loss\n    if is_best:\n        best_fpath = best_model_path\n        # copy that checkpoint file to best path given, best_model_path\n        shutil.copyfile(f_path, best_fpath)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:34.502894Z","iopub.execute_input":"2024-05-03T07:27:34.503172Z","iopub.status.idle":"2024-05-03T07:27:34.511537Z","shell.execute_reply.started":"2024-05-03T07:27:34.503148Z","shell.execute_reply":"2024-05-03T07:27:34.510449Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = load_ckp('/kaggle/input/bert-for-capec-dataset/pytorch/bertbase/1/BERT_CAPEC.pt', model)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:23:03.955061Z","iopub.execute_input":"2024-05-03T06:23:03.955425Z","iopub.status.idle":"2024-05-03T06:23:21.847141Z","shell.execute_reply.started":"2024-05-03T06:23:03.955397Z","shell.execute_reply":"2024-05-03T06:23:21.846154Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from transformers import RobertaModel, RobertaTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:34.512830Z","iopub.execute_input":"2024-05-03T07:27:34.513174Z","iopub.status.idle":"2024-05-03T07:27:34.551960Z","shell.execute_reply.started":"2024-05-03T07:27:34.513140Z","shell.execute_reply":"2024-05-03T07:27:34.551197Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class BERTClass(torch.nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n        self.pre_classifier = torch.nn.Linear(768, 768)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.linear = torch.nn.Linear(768, 6)\n    \n    def forward(self, input_ids, attn_mask, token_type_ids):\n        output = self.bert_model(\n            input_ids, \n            attention_mask=attn_mask, \n            token_type_ids=token_type_ids\n        )\n        hidden_state = output[0]\n        pooler = hidden_state[:, 0]\n        pooler = self.pre_classifier(pooler)\n        pooler = torch.nn.ReLU()(pooler)\n        pooler = self.dropout(pooler)\n        output = self.linear(pooler)\n        return output\n\nmodel = BERTClass()\n\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:35.005802Z","iopub.execute_input":"2024-05-03T07:27:35.006116Z","iopub.status.idle":"2024-05-03T07:27:38.524551Z","shell.execute_reply.started":"2024-05-03T07:27:35.006089Z","shell.execute_reply":"2024-05-03T07:27:38.523542Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce16323b2c2e428187541c6ec4f25bc5"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"BERTClass(\n  (bert_model): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (linear): Linear(in_features=768, out_features=6, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:44.559766Z","iopub.execute_input":"2024-05-03T07:27:44.560768Z","iopub.status.idle":"2024-05-03T07:27:44.569584Z","shell.execute_reply.started":"2024-05-03T07:27:44.560721Z","shell.execute_reply":"2024-05-03T07:27:44.567945Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"val_targets=[]\nval_outputs=[]","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:45.885389Z","iopub.execute_input":"2024-05-03T07:27:45.886406Z","iopub.status.idle":"2024-05-03T07:27:45.891111Z","shell.execute_reply.started":"2024-05-03T07:27:45.886358Z","shell.execute_reply":"2024-05-03T07:27:45.889926Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def train_model(n_epochs, training_loader, validation_loader, model, \n                optimizer, checkpoint_path, best_model_path):\n   \n  # initialize tracker for minimum validation loss\n    valid_loss_min = np.Inf\n   \n \n    for epoch in range(1, n_epochs+1):\n        train_loss = 0\n        valid_loss = 0\n        model.train()\n        print('############# Epoch {}: Training Start   #############'.format(epoch))\n        for batch_idx, data in enumerate(training_loader):\n            #print('yyy epoch', batch_idx)\n            ids = data['input_ids'].to(device, dtype = torch.long)\n            mask = data['attention_mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n\n            outputs = model(ids, mask, token_type_ids)\n\n            optimizer.zero_grad()\n            loss = loss_fn(outputs, targets)\n            #if batch_idx%5000==0:\n             #   print(f'Epoch: {epoch}, Training Loss:  {loss.item()}')\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            #print('before loss data in training', loss.item(), train_loss)\n            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n            #print('after loss data in training', loss.item(), train_loss)\n            \n    print('############# Epoch {}: Training End     #############'.format(epoch))\n    \n    print('############# Epoch {}: Validation Start   #############'.format(epoch))\n    ######################    \n    # validate the model #\n    ######################\n \n    model.eval()\n   \n    with torch.no_grad():\n        for batch_idx, data in enumerate(validation_loader, 0):\n            ids = data['input_ids'].to(device, dtype = torch.long)\n            mask = data['attention_mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            outputs = model(ids, mask, token_type_ids)\n\n            loss = loss_fn(outputs, targets)\n            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n            val_targets.extend(targets.cpu().detach().numpy().tolist())\n            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n\n        print('############# Epoch {}: Validation End     #############'.format(epoch))\n        # calculate average losses\n        #print('before cal avg train loss', train_loss)\n        if len(training_loader) > 0:\n            train_loss = train_loss/len(training_loader)\n        if len(validation_loader) > 0:\n            valid_loss = valid_loss/len(validation_loader)\n        # print training/validation statistics \n        print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n            epoch, \n            train_loss,\n            valid_loss\n            ))\n\n        # create checkpoint variable and add important data\n        checkpoint = {\n            'epoch': epoch + 1,\n            'valid_loss_min': valid_loss,\n            'state_dict': model.state_dict(),\n            'optimizer': optimizer.state_dict()\n        }\n\n        # save checkpoint\n        save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n\n        ## TODO: save the model if validation loss has decreased\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n            # save checkpoint as best model\n            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n            valid_loss_min = valid_loss\n\n        print('############# Epoch {}  Done   #############\\n'.format(epoch))\n\n        return model","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:47.154030Z","iopub.execute_input":"2024-05-03T07:27:47.154381Z","iopub.status.idle":"2024-05-03T07:27:47.172030Z","shell.execute_reply.started":"2024-05-03T07:27:47.154352Z","shell.execute_reply":"2024-05-03T07:27:47.171130Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"ckpt_path = \"/kaggle/working/curr_ckpt\"\nbest_model_path = \"/kaggle/working/best_model.pt\"","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:27:49.430674Z","iopub.execute_input":"2024-05-03T07:27:49.431010Z","iopub.status.idle":"2024-05-03T07:27:49.435234Z","shell.execute_reply.started":"2024-05-03T07:27:49.430984Z","shell.execute_reply":"2024-05-03T07:27:49.434316Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import time\nt = time.time()\ntrained_model = train_model(EPOCHS, train_data_loader, val_data_loader, model, optimizer, ckpt_path, best_model_path)\nprint(time.time()-t)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T07:28:18.800498Z","iopub.execute_input":"2024-05-03T07:28:18.800869Z","iopub.status.idle":"2024-05-03T08:27:24.553901Z","shell.execute_reply.started":"2024-05-03T07:28:18.800838Z","shell.execute_reply":"2024-05-03T08:27:24.552938Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"############# Epoch 1: Training Start   #############\n############# Epoch 2: Training Start   #############\n############# Epoch 2: Training End     #############\n############# Epoch 2: Validation Start   #############\n############# Epoch 2: Validation End     #############\nEpoch: 2 \tAvgerage Training Loss: 0.000012 \tAverage Validation Loss: 0.000028\nValidation loss decreased (inf --> 0.000028).  Saving model ...\n############# Epoch 2  Done   #############\n\n3545.7485885620117\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report,accuracy_score, f1_score","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:20:45.454701Z","iopub.execute_input":"2024-05-03T06:20:45.455069Z","iopub.status.idle":"2024-05-03T06:20:46.102850Z","shell.execute_reply.started":"2024-05-03T06:20:45.455041Z","shell.execute_reply":"2024-05-03T06:20:46.101733Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n#     y_true1 = y_true.to_numpy()\n#     y_pred1 = y_pred.toarray()\n    acc_list = []\n    \n    for i in range(y_true.shape[0]):\n        set_true = set( np.where(y_true[i])[0] )\n        set_pred = set( np.where(y_pred[i])[0] )\n        tmp_a = None\n        if len(set_true) == 0 and len(set_pred) == 0:\n            tmp_a = 1\n        else:\n            tmp_a = len(set_true.intersection(set_pred))/float(len(set_true.union(set_pred)))\n        acc_list.append(tmp_a)\n    return np.mean(acc_list)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:20:49.074224Z","iopub.execute_input":"2024-05-03T06:20:49.074936Z","iopub.status.idle":"2024-05-03T06:20:49.083296Z","shell.execute_reply.started":"2024-05-03T06:20:49.074899Z","shell.execute_reply":"2024-05-03T06:20:49.082378Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import hamming_loss,classification_report\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report,accuracy_score, f1_score, hamming_loss","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:20:51.499846Z","iopub.execute_input":"2024-05-03T06:20:51.500546Z","iopub.status.idle":"2024-05-03T06:20:51.505128Z","shell.execute_reply.started":"2024-05-03T06:20:51.500501Z","shell.execute_reply":"2024-05-03T06:20:51.504002Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def save_classification(y_test, y_pred, labels):\n    if isinstance(y_pred, np.ndarray) == False:\n        y_pred = y_pred.toarray()\n\n    def accuracy(y_true, y_pred):\n        temp = 0\n        for i in range(y_true.shape[0]):\n            numerator = sum(np.logical_and(y_true[i], y_pred[i]))\n            denominator = sum(np.logical_or(y_true[i], y_pred[i]))\n            if denominator != 0:\n                temp += numerator / denominator\n        return temp / y_true.shape[0]\n\n    out = classification_report(y_test,y_pred, output_dict=True, target_names=labels)\n    total_support = out['samples avg']['support']\n\n    mr = accuracy_score(y_test, y_pred)\n    acc = accuracy(y_test,y_pred)\n    hm = hamming_loss(y_test, y_pred)\n\n    out['Exact Match Ratio'] = {'precision': mr, 'recall': mr, 'f1-score': mr, 'support': total_support}\n    out['Hamming Loss'] = {'precision': hm, 'recall': hm, 'f1-score': hm, 'support': total_support}\n    out['Accuracy'] = {'precision': acc, 'recall': acc, 'f1-score': acc, 'support': total_support}\n    out_df = pd.DataFrame(out).transpose()\n    print(out_df)\n\n    \n\n    return out_df","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:20:53.619627Z","iopub.execute_input":"2024-05-03T06:20:53.620204Z","iopub.status.idle":"2024-05-03T06:20:53.632883Z","shell.execute_reply.started":"2024-05-03T06:20:53.620164Z","shell.execute_reply":"2024-05-03T06:20:53.631494Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def predict(testing_loader, model):\n    print(\"\\nPredicting...\")\n    # deactivate dropout layers\n    model.eval()\n\n    # empty list to save the model predictions\n    total_preds = []\n    total_labels = []\n    # iterate over batches\n    for step, batch in enumerate(testing_loader):\n        # push the batch to gpu\n        ids = batch['input_ids'].to(device)\n        mask = batch['attention_mask'].to(device)\n        token_type_ids = batch['token_type_ids'].to(device)\n        targets = batch['targets'].to(device)\n\n        # deactivate autograd\n        with torch.no_grad():\n            # model predictions\n            output = model(ids, mask, token_type_ids)\n            final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n            \n            total_preds += list(final_output)\n            total_labels += targets.tolist()\n\n    return total_labels, total_preds","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:20:57.499795Z","iopub.execute_input":"2024-05-03T06:20:57.500650Z","iopub.status.idle":"2024-05-03T06:20:57.507635Z","shell.execute_reply.started":"2024-05-03T06:20:57.500613Z","shell.execute_reply":"2024-05-03T06:20:57.506721Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:23:43.916049Z","iopub.execute_input":"2024-05-03T06:23:43.916460Z","iopub.status.idle":"2024-05-03T06:23:43.920978Z","shell.execute_reply.started":"2024-05-03T06:23:43.916428Z","shell.execute_reply":"2024-05-03T06:23:43.920013Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"t = time.time()\ntotal_labels, total_preds = predict(test_data_loader, model)\nprint(time.time()-t)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:24:36.143165Z","iopub.execute_input":"2024-05-03T06:24:36.143493Z","iopub.status.idle":"2024-05-03T06:28:02.832632Z","shell.execute_reply.started":"2024-05-03T06:24:36.143469Z","shell.execute_reply":"2024-05-03T06:28:02.831608Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"\nPredicting...\n206.6841902732849\n","output_type":"stream"}]},{"cell_type":"code","source":"save_classification(y_test=np.array(np.nan_to_num(total_labels)), y_pred=np.array(np.round(total_preds)), labels=target_list)","metadata":{"execution":{"iopub.status.busy":"2024-05-01T06:07:08.226057Z","iopub.execute_input":"2024-05-01T06:07:08.226375Z","iopub.status.idle":"2024-05-01T06:07:08.537398Z","shell.execute_reply.started":"2024-05-01T06:07:08.226349Z","shell.execute_reply":"2024-05-01T06:07:08.536384Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"                           precision    recall  f1-score  support\n000 - Normal                0.984889  0.978645  0.981757   2997.0\n126 - Path Traversal        0.999676  0.970135  0.984684   3181.0\n242 - Code Injection        1.000000  0.997442  0.998719   3127.0\n274 - HTTP Verb Tampering   1.000000  1.000000  1.000000   1111.0\n66 - SQL Injection          0.989886  0.969639  0.979658   3129.0\n88 - OS Command Injection   1.000000  0.981545  0.990686   1463.0\nmicro avg                   0.994796  0.980744  0.987720  15008.0\nmacro avg                   0.995742  0.982901  0.989251  15008.0\nweighted avg                0.994805  0.980744  0.987695  15008.0\nsamples avg                 0.979996  0.979852  0.979900  15008.0\nExact Match Ratio           0.979709  0.979709  0.979709  15008.0\nHamming Loss                0.004374  0.004374  0.004374  15008.0\nAccuracy                    0.979852  0.979852  0.979852  15008.0\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                           precision    recall  f1-score  support\n000 - Normal                0.984889  0.978645  0.981757   2997.0\n126 - Path Traversal        0.999676  0.970135  0.984684   3181.0\n242 - Code Injection        1.000000  0.997442  0.998719   3127.0\n274 - HTTP Verb Tampering   1.000000  1.000000  1.000000   1111.0\n66 - SQL Injection          0.989886  0.969639  0.979658   3129.0\n88 - OS Command Injection   1.000000  0.981545  0.990686   1463.0\nmicro avg                   0.994796  0.980744  0.987720  15008.0\nmacro avg                   0.995742  0.982901  0.989251  15008.0\nweighted avg                0.994805  0.980744  0.987695  15008.0\nsamples avg                 0.979996  0.979852  0.979900  15008.0\nExact Match Ratio           0.979709  0.979709  0.979709  15008.0\nHamming Loss                0.004374  0.004374  0.004374  15008.0\nAccuracy                    0.979852  0.979852  0.979852  15008.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>000 - Normal</th>\n      <td>0.984889</td>\n      <td>0.978645</td>\n      <td>0.981757</td>\n      <td>2997.0</td>\n    </tr>\n    <tr>\n      <th>126 - Path Traversal</th>\n      <td>0.999676</td>\n      <td>0.970135</td>\n      <td>0.984684</td>\n      <td>3181.0</td>\n    </tr>\n    <tr>\n      <th>242 - Code Injection</th>\n      <td>1.000000</td>\n      <td>0.997442</td>\n      <td>0.998719</td>\n      <td>3127.0</td>\n    </tr>\n    <tr>\n      <th>274 - HTTP Verb Tampering</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1111.0</td>\n    </tr>\n    <tr>\n      <th>66 - SQL Injection</th>\n      <td>0.989886</td>\n      <td>0.969639</td>\n      <td>0.979658</td>\n      <td>3129.0</td>\n    </tr>\n    <tr>\n      <th>88 - OS Command Injection</th>\n      <td>1.000000</td>\n      <td>0.981545</td>\n      <td>0.990686</td>\n      <td>1463.0</td>\n    </tr>\n    <tr>\n      <th>micro avg</th>\n      <td>0.994796</td>\n      <td>0.980744</td>\n      <td>0.987720</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>macro avg</th>\n      <td>0.995742</td>\n      <td>0.982901</td>\n      <td>0.989251</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.994805</td>\n      <td>0.980744</td>\n      <td>0.987695</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>samples avg</th>\n      <td>0.979996</td>\n      <td>0.979852</td>\n      <td>0.979900</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>Exact Match Ratio</th>\n      <td>0.979709</td>\n      <td>0.979709</td>\n      <td>0.979709</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>Hamming Loss</th>\n      <td>0.004374</td>\n      <td>0.004374</td>\n      <td>0.004374</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.979852</td>\n      <td>0.979852</td>\n      <td>0.979852</td>\n      <td>15008.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}