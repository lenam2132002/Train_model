{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6534386,"sourceType":"datasetVersion","datasetId":3751577},{"sourceId":7943960,"sourceType":"datasetVersion","datasetId":4670372},{"sourceId":7961167,"sourceType":"datasetVersion","datasetId":4683242},{"sourceId":42901,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":36041}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:23:51.453161Z","iopub.execute_input":"2024-06-15T09:23:51.453661Z","iopub.status.idle":"2024-06-15T09:24:05.391343Z","shell.execute_reply.started":"2024-06-15T09:23:51.453634Z","shell.execute_reply":"2024-06-15T09:24:05.389995Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport shutil\nimport sys   ","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:24:05.393523Z","iopub.execute_input":"2024-06-15T09:24:05.393868Z","iopub.status.idle":"2024-06-15T09:24:09.318188Z","shell.execute_reply.started":"2024-06-15T09:24:05.393821Z","shell.execute_reply":"2024-06-15T09:24:09.317404Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_path = \"/kaggle/input/code-injection-6labels-balance/code_injection_6labels_balance.csv\"\n","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:24:09.319368Z","iopub.execute_input":"2024-06-15T09:24:09.319845Z","iopub.status.idle":"2024-06-15T09:24:09.324240Z","shell.execute_reply.started":"2024-06-15T09:24:09.319816Z","shell.execute_reply":"2024-06-15T09:24:09.323194Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(train_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:24:14.525816Z","iopub.execute_input":"2024-06-15T09:24:14.526147Z","iopub.status.idle":"2024-06-15T09:24:14.813641Z","shell.execute_reply.started":"2024-06-15T09:24:14.526120Z","shell.execute_reply":"2024-06-15T09:24:14.812821Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"target_list = [\"000 - Normal\", '126 - Path Traversal', \n               '242 - Code Injection', '274 - HTTP Verb Tampering', \n               '66 - SQL Injection', '88 - OS Command Injection']","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:24:17.407098Z","iopub.execute_input":"2024-06-15T09:24:17.407912Z","iopub.status.idle":"2024-06-15T09:24:17.411831Z","shell.execute_reply.started":"2024-06-15T09:24:17.407878Z","shell.execute_reply":"2024-06-15T09:24:17.410917Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:44:41.860791Z","iopub.execute_input":"2024-05-03T06:44:41.861554Z","iopub.status.idle":"2024-05-03T06:44:41.894371Z","shell.execute_reply.started":"2024-05-03T06:44:41.861520Z","shell.execute_reply":"2024-05-03T06:44:41.893384Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0                                               text  \\\n0               0                                              GET /   \n1               1  GET /blog/index.php/2020/04/04/voluptatum-repr...   \n2               2                           GET /blog/xmlrpc.php?rsd   \n3               3  POST /blog/index.php/my-account/user-logout/?_...   \n4               4  GET /blog/index.php/2020/04/04/nihil-tenetur-e...   \n...           ...                                                ...   \n69730       69730  POST /blog/index.php/my-account/user-logout/?_...   \n69731       69731  POST /blog/index.php/my-account/user-logout/?_...   \n69732       69732  POST /blog/index.php/my-account/user-logout/?_...   \n69733       69733  POST /blog/index.php/my-account/user-logout/?_...   \n69734       69734  GET /blog/index.php/my-account/edit-profile%28...   \n\n       000 - Normal  126 - Path Traversal  242 - Code Injection  \\\n0                 1                     0                     0   \n1                 1                     0                     0   \n2                 1                     0                     0   \n3                 0                     0                     0   \n4                 1                     0                     0   \n...             ...                   ...                   ...   \n69730             0                     1                     0   \n69731             0                     1                     0   \n69732             0                     1                     0   \n69733             0                     1                     0   \n69734             0                     0                     0   \n\n       274 - HTTP Verb Tampering  66 - SQL Injection  \\\n0                              0                   0   \n1                              0                   0   \n2                              0                   0   \n3                              0                   0   \n4                              0                   0   \n...                          ...                 ...   \n69730                          0                   0   \n69731                          0                   0   \n69732                          0                   0   \n69733                          0                   0   \n69734                          0                   1   \n\n       88 - OS Command Injection  \n0                              0  \n1                              0  \n2                              0  \n3                              1  \n4                              0  \n...                          ...  \n69730                          1  \n69731                          1  \n69732                          1  \n69733                          1  \n69734                          0  \n\n[69735 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>000 - Normal</th>\n      <th>126 - Path Traversal</th>\n      <th>242 - Code Injection</th>\n      <th>274 - HTTP Verb Tampering</th>\n      <th>66 - SQL Injection</th>\n      <th>88 - OS Command Injection</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>GET /</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>GET /blog/index.php/2020/04/04/voluptatum-repr...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>GET /blog/xmlrpc.php?rsd</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>POST /blog/index.php/my-account/user-logout/?_...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>GET /blog/index.php/2020/04/04/nihil-tenetur-e...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>69730</th>\n      <td>69730</td>\n      <td>POST /blog/index.php/my-account/user-logout/?_...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>69731</th>\n      <td>69731</td>\n      <td>POST /blog/index.php/my-account/user-logout/?_...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>69732</th>\n      <td>69732</td>\n      <td>POST /blog/index.php/my-account/user-logout/?_...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>69733</th>\n      <td>69733</td>\n      <td>POST /blog/index.php/my-account/user-logout/?_...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>69734</th>\n      <td>69734</td>\n      <td>GET /blog/index.php/my-account/edit-profile%28...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>69735 rows Ã— 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df1 = pd.read_csv(train_path)\ndf[df[target_list] == 1].count()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:44:45.544407Z","iopub.execute_input":"2024-05-03T06:44:45.544817Z","iopub.status.idle":"2024-05-03T06:44:45.605719Z","shell.execute_reply.started":"2024-05-03T06:44:45.544785Z","shell.execute_reply":"2024-05-03T06:44:45.604569Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0                       0\ntext                             0\n000 - Normal                 14694\n126 - Path Traversal         15839\n242 - Code Injection         15747\n274 - HTTP Verb Tampering     5437\n66 - SQL Injection           15951\n88 - OS Command Injection     7317\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train, validate, test = np.split(df.sample(frac=1, random_state=42),[int(.6*len(df)), int(.8*len(df))])","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:24:24.483785Z","iopub.execute_input":"2024-06-15T09:24:24.484796Z","iopub.status.idle":"2024-06-15T09:24:24.518352Z","shell.execute_reply.started":"2024-06-15T09:24:24.484721Z","shell.execute_reply":"2024-06-15T09:24:24.517371Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train[train[target_list] == 1].count()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T01:00:15.154476Z","iopub.execute_input":"2024-06-13T01:00:15.155338Z","iopub.status.idle":"2024-06-13T01:00:15.207709Z","shell.execute_reply.started":"2024-06-13T01:00:15.155299Z","shell.execute_reply":"2024-06-13T01:00:15.206822Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0                      0\ntext                            0\n000 - Normal                 8755\n126 - Path Traversal         9499\n242 - Code Injection         9440\n274 - HTTP Verb Tampering    3206\n66 - SQL Injection           9654\n88 - OS Command Injection    4402\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"validate[validate[target_list] == 1].count()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T01:00:35.152590Z","iopub.execute_input":"2024-06-13T01:00:35.153247Z","iopub.status.idle":"2024-06-13T01:00:35.174355Z","shell.execute_reply.started":"2024-06-13T01:00:35.153217Z","shell.execute_reply":"2024-06-13T01:00:35.173454Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0                      0\ntext                            0\n000 - Normal                 2942\n126 - Path Traversal         3159\n242 - Code Injection         3180\n274 - HTTP Verb Tampering    1120\n66 - SQL Injection           3168\n88 - OS Command Injection    1452\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"test[test[target_list] == 1].count()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T01:00:38.870978Z","iopub.execute_input":"2024-06-13T01:00:38.871860Z","iopub.status.idle":"2024-06-13T01:00:38.891010Z","shell.execute_reply.started":"2024-06-13T01:00:38.871821Z","shell.execute_reply":"2024-06-13T01:00:38.890156Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0                      0\ntext                            0\n000 - Normal                 2997\n126 - Path Traversal         3181\n242 - Code Injection         3127\n274 - HTTP Verb Tampering    1111\n66 - SQL Injection           3129\n88 - OS Command Injection    1463\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# hyperparameters\nMAX_LEN = 256\nTRAIN_BATCH_SIZE = 32\nVALID_BATCH_SIZE = 32\nEPOCHS = 2\nLEARNING_RATE = 1e-05","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:44:52.248013Z","iopub.execute_input":"2024-05-03T06:44:52.248935Z","iopub.status.idle":"2024-05-03T06:44:52.253508Z","shell.execute_reply.started":"2024-05-03T06:44:52.248899Z","shell.execute_reply":"2024-05-03T06:44:52.252493Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModel\nfrom transformers import BertTokenizer, BertModel","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:44:54.094138Z","iopub.execute_input":"2024-05-03T06:44:54.094492Z","iopub.status.idle":"2024-05-03T06:45:06.065080Z","shell.execute_reply.started":"2024-05-03T06:44:54.094464Z","shell.execute_reply":"2024-05-03T06:45:06.064237Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('jackaduma/SecBERT')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:45:06.066715Z","iopub.execute_input":"2024-05-03T06:45:06.067034Z","iopub.status.idle":"2024-05-03T06:45:06.898048Z","shell.execute_reply.started":"2024-05-03T06:45:06.067006Z","shell.execute_reply":"2024-05-03T06:45:06.897156Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/467 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3633c341dc6544d7bace76ab32c97bc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.txt:   0%|          | 0.00/378k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd4b41cb346b42069ad3021ef9c75771"}},"metadata":{}}]},{"cell_type":"code","source":"class CustomDataset(torch.utils.data.Dataset):\n\n    def __init__(self, df, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.df = df\n        self.title = df['text']\n        self.targets = self.df[target_list].values\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.title)\n\n    def __getitem__(self, index):\n        title = str(self.title[index])\n        title = \" \".join(title.split())\n\n        inputs = self.tokenizer.encode_plus(\n            title,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True,\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': inputs['input_ids'].flatten(),\n            'attention_mask': inputs['attention_mask'].flatten(),\n            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n            'targets': torch.FloatTensor(self.targets[index])\n        }","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:45:06.899315Z","iopub.execute_input":"2024-05-03T06:45:06.899685Z","iopub.status.idle":"2024-05-03T06:45:06.908376Z","shell.execute_reply.started":"2024-05-03T06:45:06.899645Z","shell.execute_reply":"2024-05-03T06:45:06.907422Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test.to_csv('test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:24:55.860136Z","iopub.execute_input":"2024-06-15T09:24:55.860521Z","iopub.status.idle":"2024-06-15T09:24:56.006958Z","shell.execute_reply.started":"2024-06-15T09:24:55.860489Z","shell.execute_reply":"2024-06-15T09:24:56.006126Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train = train.reset_index(drop=True)\nvalidate = validate.reset_index(drop=True)\ntest = test.reset_index(drop=True)\n\ntrain = CustomDataset(train, tokenizer, MAX_LEN)\nvalidate= CustomDataset(validate, tokenizer, MAX_LEN)\ntest = CustomDataset(test, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:24:38.071942Z","iopub.execute_input":"2024-06-15T09:24:38.072655Z","iopub.status.idle":"2024-06-15T09:24:38.081351Z","shell.execute_reply.started":"2024-06-15T09:24:38.072610Z","shell.execute_reply":"2024-06-15T09:24:38.080272Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data_loader = torch.utils.data.DataLoader(train, \n    batch_size=TRAIN_BATCH_SIZE,\n    shuffle=True,\n    num_workers=0\n)\n\nval_data_loader = torch.utils.data.DataLoader(validate, \n    batch_size=VALID_BATCH_SIZE,\n    shuffle=False,\n    num_workers=0\n)\ntest_data_loader = torch.utils.data.DataLoader(test, \n    batch_size=VALID_BATCH_SIZE,\n    shuffle=False,\n    num_workers=0\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:45:06.934373Z","iopub.execute_input":"2024-05-03T06:45:06.934776Z","iopub.status.idle":"2024-05-03T06:45:06.941758Z","shell.execute_reply.started":"2024-05-03T06:45:06.934741Z","shell.execute_reply":"2024-05-03T06:45:06.940711Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:45:08.354715Z","iopub.execute_input":"2024-05-03T06:45:08.355114Z","iopub.status.idle":"2024-05-03T06:45:08.415468Z","shell.execute_reply.started":"2024-05-03T06:45:08.355075Z","shell.execute_reply":"2024-05-03T06:45:08.414228Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"def load_ckp(checkpoint_fpath, model):\n    \"\"\"\n    checkpoint_path: path to save checkpoint\n    model: model that we want to load checkpoint parameters into       \n    optimizer: optimizer we defined in previous training\n    \"\"\"\n    # load check point\n    checkpoint = torch.load(checkpoint_fpath)\n    # initialize state_dict from checkpoint to model\n    model.load_state_dict(checkpoint['state_dict'])\n    # initialize optimizer from checkpoint to optimizer\n#     optimizer.load_state_dict(checkpoint['optimizer'])\n    # initialize valid_loss_min from checkpoint to valid_loss_min\n#     valid_loss_min = checkpoint['valid_loss_min']\n    # return model, optimizer, epoch value, min validation loss \n    return model\n# , optimizer, checkpoint['epoch'], valid_loss_min.item()\n\ndef save_ckp(state, is_best, checkpoint_path, best_model_path):\n    \"\"\"\n    state: checkpoint we want to save\n    is_best: is this the best checkpoint; min validation loss\n    checkpoint_path: path to save checkpoint\n    best_model_path: path to save best model\n    \"\"\"\n    f_path = checkpoint_path\n    # save checkpoint data to the path given, checkpoint_path\n    torch.save(state, f_path)\n    # if it is a best model, min validation loss\n    if is_best:\n        best_fpath = best_model_path\n        # copy that checkpoint file to best path given, best_model_path\n        shutil.copyfile(f_path, best_fpath)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:45:25.207945Z","iopub.execute_input":"2024-05-03T06:45:25.208623Z","iopub.status.idle":"2024-05-03T06:45:25.215707Z","shell.execute_reply.started":"2024-05-03T06:45:25.208587Z","shell.execute_reply":"2024-05-03T06:45:25.214706Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class BERTClass(torch.nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.bert_model = AutoModel.from_pretrained('jackaduma/SecBERT')\n        self.dropout = torch.nn.Dropout(0.3)\n        self.linear = torch.nn.Linear(768, 6)\n    \n    def forward(self, input_ids, attn_mask, token_type_ids):\n        output = self.bert_model(\n            input_ids, \n            attention_mask=attn_mask, \n            token_type_ids=token_type_ids\n        )\n        output_dropout = self.dropout(output.pooler_output)\n        output = self.linear(output_dropout)\n        return output\n\nmodel = BERTClass()\n\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:45:27.977217Z","iopub.execute_input":"2024-05-03T06:45:27.978003Z","iopub.status.idle":"2024-05-03T06:45:33.575039Z","shell.execute_reply.started":"2024-05-03T06:45:27.977959Z","shell.execute_reply":"2024-05-03T06:45:33.573488Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/336M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18fe2ac57ff64aada14bbcc7738ca383"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"BERTClass(\n  (bert_model): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(52000, 768, padding_idx=0)\n      (position_embeddings): Embedding(514, 768)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-5): 6 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (linear): Linear(in_features=768, out_features=6, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"model = load_ckp('/kaggle/input/bert-for-capec-dataset/pytorch/secbert/1/SecBert_6labels_balance.pt', model)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:45:54.773941Z","iopub.execute_input":"2024-05-03T06:45:54.774678Z","iopub.status.idle":"2024-05-03T06:46:01.662924Z","shell.execute_reply.started":"2024-05-03T06:45:54.774642Z","shell.execute_reply":"2024-05-03T06:46:01.662093Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n\noptimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:49:57.216181Z","iopub.execute_input":"2024-05-03T06:49:57.217115Z","iopub.status.idle":"2024-05-03T06:49:57.224385Z","shell.execute_reply.started":"2024-05-03T06:49:57.217067Z","shell.execute_reply":"2024-05-03T06:49:57.223255Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"val_targets=[]\nval_outputs=[]","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:49:58.967530Z","iopub.execute_input":"2024-05-03T06:49:58.967925Z","iopub.status.idle":"2024-05-03T06:49:58.972249Z","shell.execute_reply.started":"2024-05-03T06:49:58.967894Z","shell.execute_reply":"2024-05-03T06:49:58.971234Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def train_model(n_epochs, training_loader, validation_loader, model, \n                optimizer, checkpoint_path, best_model_path):\n   \n  # initialize tracker for minimum validation loss\n    valid_loss_min = np.Inf\n   \n \n    for epoch in range(1, n_epochs+1):\n        train_loss = 0\n        valid_loss = 0\n        model.train()\n        print('############# Epoch {}: Training Start   #############'.format(epoch))\n        for batch_idx, data in enumerate(training_loader):\n            #print('yyy epoch', batch_idx)\n            ids = data['input_ids'].to(device, dtype = torch.long)\n            mask = data['attention_mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n\n            outputs = model(ids, mask, token_type_ids)\n\n            optimizer.zero_grad()\n            loss = loss_fn(outputs, targets)\n            #if batch_idx%5000==0:\n             #   print(f'Epoch: {epoch}, Training Loss:  {loss.item()}')\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            #print('before loss data in training', loss.item(), train_loss)\n            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n            #print('after loss data in training', loss.item(), train_loss)\n            \n    print('############# Epoch {}: Training End     #############'.format(epoch))\n    \n    print('############# Epoch {}: Validation Start   #############'.format(epoch))\n    ######################    \n    # validate the model #\n    ######################\n \n    model.eval()\n   \n    with torch.no_grad():\n        for batch_idx, data in enumerate(validation_loader, 0):\n            ids = data['input_ids'].to(device, dtype = torch.long)\n            mask = data['attention_mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            outputs = model(ids, mask, token_type_ids)\n\n            loss = loss_fn(outputs, targets)\n            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n            val_targets.extend(targets.cpu().detach().numpy().tolist())\n            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n\n        print('############# Epoch {}: Validation End     #############'.format(epoch))\n        # calculate average losses\n        #print('before cal avg train loss', train_loss)\n        if len(training_loader) > 0:\n            train_loss = train_loss/len(training_loader)\n        if len(validation_loader) > 0:\n            valid_loss = valid_loss/len(validation_loader)\n        # print training/validation statistics \n        print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n            epoch, \n            train_loss,\n            valid_loss\n            ))\n\n        # create checkpoint variable and add important data\n        checkpoint = {\n            'epoch': epoch + 1,\n            'valid_loss_min': valid_loss,\n            'state_dict': model.state_dict(),\n            'optimizer': optimizer.state_dict()\n        }\n\n        # save checkpoint\n        save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n\n        ## TODO: save the model if validation loss has decreased\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n            # save checkpoint as best model\n            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n            valid_loss_min = valid_loss\n\n        print('############# Epoch {}  Done   #############\\n'.format(epoch))\n\n        return model","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:50:01.130463Z","iopub.execute_input":"2024-05-03T06:50:01.131260Z","iopub.status.idle":"2024-05-03T06:50:01.150061Z","shell.execute_reply.started":"2024-05-03T06:50:01.131209Z","shell.execute_reply":"2024-05-03T06:50:01.148725Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"ckpt_path = \"/kaggle/working/curr_ckpt\"\nbest_model_path = \"/kaggle/working/best_model.pt\"","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:50:05.106711Z","iopub.execute_input":"2024-05-03T06:50:05.107090Z","iopub.status.idle":"2024-05-03T06:50:05.111667Z","shell.execute_reply.started":"2024-05-03T06:50:05.107061Z","shell.execute_reply":"2024-05-03T06:50:05.110582Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"t = time.time()\ntrained_model = train_model(EPOCHS, train_data_loader, val_data_loader, model, optimizer, ckpt_path, best_model_path)\nprint(time.time()-t)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:50:34.965757Z","iopub.execute_input":"2024-05-03T06:50:34.966637Z","iopub.status.idle":"2024-05-03T07:21:58.443871Z","shell.execute_reply.started":"2024-05-03T06:50:34.966604Z","shell.execute_reply":"2024-05-03T07:21:58.442866Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"############# Epoch 1: Training Start   #############\n############# Epoch 2: Training Start   #############\n############# Epoch 2: Training End     #############\n############# Epoch 2: Validation Start   #############\n############# Epoch 2: Validation End     #############\nEpoch: 2 \tAvgerage Training Loss: 0.000009 \tAverage Validation Loss: 0.000026\nValidation loss decreased (inf --> 0.000026).  Saving model ...\n############# Epoch 2  Done   #############\n\n1883.4724218845367\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report,accuracy_score, f1_score","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:46:06.169866Z","iopub.execute_input":"2024-05-03T06:46:06.170233Z","iopub.status.idle":"2024-05-03T06:46:06.566637Z","shell.execute_reply.started":"2024-05-03T06:46:06.170202Z","shell.execute_reply":"2024-05-03T06:46:06.565779Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n#     y_true1 = y_true.to_numpy()\n#     y_pred1 = y_pred.toarray()\n    acc_list = []\n    \n    for i in range(y_true.shape[0]):\n        set_true = set( np.where(y_true[i])[0] )\n        set_pred = set( np.where(y_pred[i])[0] )\n        tmp_a = None\n        if len(set_true) == 0 and len(set_pred) == 0:\n            tmp_a = 1\n        else:\n            tmp_a = len(set_true.intersection(set_pred))/float(len(set_true.union(set_pred)))\n        acc_list.append(tmp_a)\n    return np.mean(acc_list)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:46:07.802857Z","iopub.execute_input":"2024-05-03T06:46:07.803756Z","iopub.status.idle":"2024-05-03T06:46:07.810708Z","shell.execute_reply.started":"2024-05-03T06:46:07.803722Z","shell.execute_reply":"2024-05-03T06:46:07.809652Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import hamming_loss,classification_report\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report,accuracy_score, f1_score, hamming_loss","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:46:10.394813Z","iopub.execute_input":"2024-05-03T06:46:10.395275Z","iopub.status.idle":"2024-05-03T06:46:10.400416Z","shell.execute_reply.started":"2024-05-03T06:46:10.395241Z","shell.execute_reply":"2024-05-03T06:46:10.399266Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def save_classification(y_test, y_pred, labels):\n    if isinstance(y_pred, np.ndarray) == False:\n        y_pred = y_pred.toarray()\n\n    def accuracy(y_true, y_pred):\n        temp = 0\n        for i in range(y_true.shape[0]):\n            numerator = sum(np.logical_and(y_true[i], y_pred[i]))\n            denominator = sum(np.logical_or(y_true[i], y_pred[i]))\n            if denominator != 0:\n                temp += numerator / denominator\n        return temp / y_true.shape[0]\n\n    out = classification_report(y_test,y_pred, output_dict=True, target_names=labels)\n    total_support = out['samples avg']['support']\n\n    mr = accuracy_score(y_test, y_pred)\n    acc = accuracy(y_test,y_pred)\n    hm = hamming_loss(y_test, y_pred)\n\n    out['Exact Match Ratio'] = {'precision': mr, 'recall': mr, 'f1-score': mr, 'support': total_support}\n    out['Hamming Loss'] = {'precision': hm, 'recall': hm, 'f1-score': hm, 'support': total_support}\n    out['Accuracy'] = {'precision': acc, 'recall': acc, 'f1-score': acc, 'support': total_support}\n    out_df = pd.DataFrame(out).transpose()\n    print(out_df)\n\n    \n\n    return out_df","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:46:12.316311Z","iopub.execute_input":"2024-05-03T06:46:12.316685Z","iopub.status.idle":"2024-05-03T06:46:12.327110Z","shell.execute_reply.started":"2024-05-03T06:46:12.316655Z","shell.execute_reply":"2024-05-03T06:46:12.326038Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def predict(testing_loader, model):\n    print(\"\\nPredicting...\")\n    # deactivate dropout layers\n    model.eval()\n\n    # empty list to save the model predictions\n    total_preds = []\n    total_labels = []\n    # iterate over batches\n    for step, batch in enumerate(testing_loader):\n        # push the batch to gpu\n        ids = batch['input_ids'].to(device)\n        mask = batch['attention_mask'].to(device)\n        token_type_ids = batch['token_type_ids'].to(device)\n        targets = batch['targets'].to(device)\n\n        # deactivate autograd\n        with torch.no_grad():\n            # model predictions\n            output = model(ids, mask, token_type_ids)\n            final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n            \n            total_preds += list(final_output)\n            total_labels += targets.tolist()\n\n    return total_labels, total_preds","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:46:16.517915Z","iopub.execute_input":"2024-05-03T06:46:16.518702Z","iopub.status.idle":"2024-05-03T06:46:16.526214Z","shell.execute_reply.started":"2024-05-03T06:46:16.518667Z","shell.execute_reply":"2024-05-03T06:46:16.525232Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import time\nt = time.time()\ntotal_labels, total_preds = predict(test_data_loader, model)\nprint(time.time()-t)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T06:46:46.605757Z","iopub.execute_input":"2024-05-03T06:46:46.606146Z","iopub.status.idle":"2024-05-03T06:48:26.156540Z","shell.execute_reply.started":"2024-05-03T06:46:46.606117Z","shell.execute_reply":"2024-05-03T06:48:26.155591Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"\nPredicting...\n99.54562330245972\n","output_type":"stream"}]},{"cell_type":"code","source":"save_classification(y_test=np.array(np.nan_to_num(total_labels)), y_pred=np.array(np.round(total_preds)), labels=target_list)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T02:49:32.371538Z","iopub.execute_input":"2024-03-28T02:49:32.372350Z","iopub.status.idle":"2024-03-28T02:49:32.728266Z","shell.execute_reply.started":"2024-03-28T02:49:32.372314Z","shell.execute_reply":"2024-03-28T02:49:32.727214Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"                           precision    recall  f1-score  support\n000 - Normal                0.994811  0.959626  0.976902   2997.0\n126 - Path Traversal        0.980818  0.980509  0.980663   3181.0\n242 - Code Injection        1.000000  0.997761  0.998879   3127.0\n274 - HTTP Verb Tampering   1.000000  1.000000  1.000000   1111.0\n66 - SQL Injection          0.995718  0.966123  0.980697   3129.0\n88 - OS Command Injection   0.980259  0.984279  0.982265   1463.0\nmicro avg                   0.992031  0.978745  0.985343  15008.0\nmacro avg                   0.991934  0.981383  0.986568  15008.0\nweighted avg                0.992081  0.978745  0.985302  15008.0\nsamples avg                 0.977307  0.977630  0.977388  15008.0\nExact Match Ratio           0.976769  0.976769  0.976769  15008.0\nHamming Loss                0.005222  0.005222  0.005222  15008.0\nAccuracy                    0.977235  0.977235  0.977235  15008.0\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                           precision    recall  f1-score  support\n000 - Normal                0.994811  0.959626  0.976902   2997.0\n126 - Path Traversal        0.980818  0.980509  0.980663   3181.0\n242 - Code Injection        1.000000  0.997761  0.998879   3127.0\n274 - HTTP Verb Tampering   1.000000  1.000000  1.000000   1111.0\n66 - SQL Injection          0.995718  0.966123  0.980697   3129.0\n88 - OS Command Injection   0.980259  0.984279  0.982265   1463.0\nmicro avg                   0.992031  0.978745  0.985343  15008.0\nmacro avg                   0.991934  0.981383  0.986568  15008.0\nweighted avg                0.992081  0.978745  0.985302  15008.0\nsamples avg                 0.977307  0.977630  0.977388  15008.0\nExact Match Ratio           0.976769  0.976769  0.976769  15008.0\nHamming Loss                0.005222  0.005222  0.005222  15008.0\nAccuracy                    0.977235  0.977235  0.977235  15008.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>000 - Normal</th>\n      <td>0.994811</td>\n      <td>0.959626</td>\n      <td>0.976902</td>\n      <td>2997.0</td>\n    </tr>\n    <tr>\n      <th>126 - Path Traversal</th>\n      <td>0.980818</td>\n      <td>0.980509</td>\n      <td>0.980663</td>\n      <td>3181.0</td>\n    </tr>\n    <tr>\n      <th>242 - Code Injection</th>\n      <td>1.000000</td>\n      <td>0.997761</td>\n      <td>0.998879</td>\n      <td>3127.0</td>\n    </tr>\n    <tr>\n      <th>274 - HTTP Verb Tampering</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1111.0</td>\n    </tr>\n    <tr>\n      <th>66 - SQL Injection</th>\n      <td>0.995718</td>\n      <td>0.966123</td>\n      <td>0.980697</td>\n      <td>3129.0</td>\n    </tr>\n    <tr>\n      <th>88 - OS Command Injection</th>\n      <td>0.980259</td>\n      <td>0.984279</td>\n      <td>0.982265</td>\n      <td>1463.0</td>\n    </tr>\n    <tr>\n      <th>micro avg</th>\n      <td>0.992031</td>\n      <td>0.978745</td>\n      <td>0.985343</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>macro avg</th>\n      <td>0.991934</td>\n      <td>0.981383</td>\n      <td>0.986568</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.992081</td>\n      <td>0.978745</td>\n      <td>0.985302</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>samples avg</th>\n      <td>0.977307</td>\n      <td>0.977630</td>\n      <td>0.977388</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>Exact Match Ratio</th>\n      <td>0.976769</td>\n      <td>0.976769</td>\n      <td>0.976769</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>Hamming Loss</th>\n      <td>0.005222</td>\n      <td>0.005222</td>\n      <td>0.005222</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.977235</td>\n      <td>0.977235</td>\n      <td>0.977235</td>\n      <td>15008.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/working/best_model.pt')\nmodel = BERTClass()\n# model.load_state_dict(torch.load('/kaggle/working/best_model.pt'))\nmodel.load_state_dict(checkpoint['state_dict'])\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T02:49:32.729604Z","iopub.execute_input":"2024-03-28T02:49:32.729998Z","iopub.status.idle":"2024-03-28T02:49:34.504523Z","shell.execute_reply.started":"2024-03-28T02:49:32.729964Z","shell.execute_reply":"2024-03-28T02:49:34.503458Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"BERTClass(\n  (bert_model): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(52000, 768, padding_idx=0)\n      (position_embeddings): Embedding(514, 768)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-5): 6 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (linear): Linear(in_features=768, out_features=6, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"total_labels, total_preds = predict(test_data_loader, model.to(device))\nsave_classification(y_test=np.array(np.nan_to_num(total_labels)), y_pred=np.array(np.round(total_preds)), labels=target_list)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T02:49:34.506438Z","iopub.execute_input":"2024-03-28T02:49:34.506791Z","iopub.status.idle":"2024-03-28T02:51:23.190716Z","shell.execute_reply.started":"2024-03-28T02:49:34.506757Z","shell.execute_reply":"2024-03-28T02:51:23.189580Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"\nPredicting...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"                           precision    recall  f1-score  support\n000 - Normal                0.994811  0.959626  0.976902   2997.0\n126 - Path Traversal        0.980818  0.980509  0.980663   3181.0\n242 - Code Injection        1.000000  0.997761  0.998879   3127.0\n274 - HTTP Verb Tampering   1.000000  1.000000  1.000000   1111.0\n66 - SQL Injection          0.995718  0.966123  0.980697   3129.0\n88 - OS Command Injection   0.980259  0.984279  0.982265   1463.0\nmicro avg                   0.992031  0.978745  0.985343  15008.0\nmacro avg                   0.991934  0.981383  0.986568  15008.0\nweighted avg                0.992081  0.978745  0.985302  15008.0\nsamples avg                 0.977307  0.977630  0.977388  15008.0\nExact Match Ratio           0.976769  0.976769  0.976769  15008.0\nHamming Loss                0.005222  0.005222  0.005222  15008.0\nAccuracy                    0.977235  0.977235  0.977235  15008.0\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                           precision    recall  f1-score  support\n000 - Normal                0.994811  0.959626  0.976902   2997.0\n126 - Path Traversal        0.980818  0.980509  0.980663   3181.0\n242 - Code Injection        1.000000  0.997761  0.998879   3127.0\n274 - HTTP Verb Tampering   1.000000  1.000000  1.000000   1111.0\n66 - SQL Injection          0.995718  0.966123  0.980697   3129.0\n88 - OS Command Injection   0.980259  0.984279  0.982265   1463.0\nmicro avg                   0.992031  0.978745  0.985343  15008.0\nmacro avg                   0.991934  0.981383  0.986568  15008.0\nweighted avg                0.992081  0.978745  0.985302  15008.0\nsamples avg                 0.977307  0.977630  0.977388  15008.0\nExact Match Ratio           0.976769  0.976769  0.976769  15008.0\nHamming Loss                0.005222  0.005222  0.005222  15008.0\nAccuracy                    0.977235  0.977235  0.977235  15008.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>000 - Normal</th>\n      <td>0.994811</td>\n      <td>0.959626</td>\n      <td>0.976902</td>\n      <td>2997.0</td>\n    </tr>\n    <tr>\n      <th>126 - Path Traversal</th>\n      <td>0.980818</td>\n      <td>0.980509</td>\n      <td>0.980663</td>\n      <td>3181.0</td>\n    </tr>\n    <tr>\n      <th>242 - Code Injection</th>\n      <td>1.000000</td>\n      <td>0.997761</td>\n      <td>0.998879</td>\n      <td>3127.0</td>\n    </tr>\n    <tr>\n      <th>274 - HTTP Verb Tampering</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1111.0</td>\n    </tr>\n    <tr>\n      <th>66 - SQL Injection</th>\n      <td>0.995718</td>\n      <td>0.966123</td>\n      <td>0.980697</td>\n      <td>3129.0</td>\n    </tr>\n    <tr>\n      <th>88 - OS Command Injection</th>\n      <td>0.980259</td>\n      <td>0.984279</td>\n      <td>0.982265</td>\n      <td>1463.0</td>\n    </tr>\n    <tr>\n      <th>micro avg</th>\n      <td>0.992031</td>\n      <td>0.978745</td>\n      <td>0.985343</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>macro avg</th>\n      <td>0.991934</td>\n      <td>0.981383</td>\n      <td>0.986568</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.992081</td>\n      <td>0.978745</td>\n      <td>0.985302</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>samples avg</th>\n      <td>0.977307</td>\n      <td>0.977630</td>\n      <td>0.977388</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>Exact Match Ratio</th>\n      <td>0.976769</td>\n      <td>0.976769</td>\n      <td>0.976769</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>Hamming Loss</th>\n      <td>0.005222</td>\n      <td>0.005222</td>\n      <td>0.005222</td>\n      <td>15008.0</td>\n    </tr>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.977235</td>\n      <td>0.977235</td>\n      <td>0.977235</td>\n      <td>15008.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink('/kaggle/working/best_model.pt')","metadata":{"execution":{"iopub.status.busy":"2024-03-28T02:54:21.511417Z","iopub.execute_input":"2024-03-28T02:54:21.512573Z","iopub.status.idle":"2024-03-28T02:54:21.519308Z","shell.execute_reply.started":"2024-03-28T02:54:21.512528Z","shell.execute_reply":"2024-03-28T02:54:21.518125Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/best_model.pt","text/html":"<a href='/kaggle/working/best_model.pt' target='_blank'>/kaggle/working/best_model.pt</a><br>"},"metadata":{}}]}]}